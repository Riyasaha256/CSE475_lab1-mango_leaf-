{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10866345,
          "sourceType": "datasetVersion",
          "datasetId": 6750631
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Mango leaf_ML",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riyasaha256/CSE475_lab1-mango_leaf-/blob/main/Mango_leaf_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "emUEnyun1mpT"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "sahariya116_mango_leafbd_path = kagglehub.dataset_download('sahariya116/mango-leafbd')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "IxuL30o51mpV"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:50:29.613446Z",
          "iopub.execute_input": "2025-03-04T02:50:29.613739Z",
          "iopub.status.idle": "2025-03-04T02:50:42.985165Z",
          "shell.execute_reply.started": "2025-03-04T02:50:29.613719Z",
          "shell.execute_reply": "2025-03-04T02:50:42.984233Z"
        },
        "id": "_f99YqyJ1mpW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/input/\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:50:42.986179Z",
          "iopub.execute_input": "2025-03-04T02:50:42.986614Z",
          "iopub.status.idle": "2025-03-04T02:50:43.114659Z",
          "shell.execute_reply.started": "2025-03-04T02:50:42.98659Z",
          "shell.execute_reply": "2025-03-04T02:50:43.113594Z"
        },
        "id": "asjsGeDt1mpW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To check the subdirectories inside MangoLeafBD Dataset"
      ],
      "metadata": {
        "id": "ddh1BPaU1mpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/input/mango-leafbd\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:50:43.116483Z",
          "iopub.execute_input": "2025-03-04T02:50:43.116748Z",
          "iopub.status.idle": "2025-03-04T02:50:43.239722Z",
          "shell.execute_reply.started": "2025-03-04T02:50:43.116723Z",
          "shell.execute_reply": "2025-03-04T02:50:43.238932Z"
        },
        "id": "CY8yoToA1mpX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cy5oX39H1mpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the dataset directory path (change if needed)\n",
        "data_dir = \"/kaggle/input/mango-leafbd\"\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(data_dir):\n",
        "    print(\"Dataset is available!\")\n",
        "    print(\"Contents:\", os.listdir(data_dir))  # List files & folders in dataset\n",
        "else:\n",
        "    print(\"Dataset not found. Check the path.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:50:43.241003Z",
          "iopub.execute_input": "2025-03-04T02:50:43.241272Z",
          "iopub.status.idle": "2025-03-04T02:50:43.247233Z",
          "shell.execute_reply.started": "2025-03-04T02:50:43.241246Z",
          "shell.execute_reply": "2025-03-04T02:50:43.246387Z"
        },
        "id": "jlMA0tN51mpY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/kaggle/input/mango-leafbd\"\n",
        "classes = os.listdir(data_dir)\n",
        "for cls in classes:\n",
        "    print(f\"Class: {cls}, Number of Images: {len(os.listdir(os.path.join(data_dir, cls)))}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:50:43.248148Z",
          "iopub.execute_input": "2025-03-04T02:50:43.248429Z",
          "iopub.status.idle": "2025-03-04T02:50:43.274087Z",
          "shell.execute_reply.started": "2025-03-04T02:50:43.248397Z",
          "shell.execute_reply": "2025-03-04T02:50:43.273357Z"
        },
        "id": "66KaGB3u1mpY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List Subdirectories Inside MangoLeafBD Dataset"
      ],
      "metadata": {
        "id": "osM-9BCi1mpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/kaggle/input/mango-leafbd/MangoLeafBD Dataset\"\n",
        "classes = os.listdir(data_dir)\n",
        "for cls in classes:\n",
        "    print(f\"Class: {cls}, Number of Images: {len(os.listdir(os.path.join(data_dir, cls)))}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:50:43.275023Z",
          "iopub.execute_input": "2025-03-04T02:50:43.275304Z",
          "iopub.status.idle": "2025-03-04T02:50:43.303414Z",
          "shell.execute_reply.started": "2025-03-04T02:50:43.275285Z",
          "shell.execute_reply": "2025-03-04T02:50:43.30282Z"
        },
        "id": "Tdwb9Ott1mpY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image size"
      ],
      "metadata": {
        "id": "elpADFBz1mpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_sizes = []\n",
        "for cls in classes:\n",
        "    for img_file in os.listdir(os.path.join(data_dir, cls)):\n",
        "        img = Image.open(os.path.join(data_dir, cls, img_file))\n",
        "        image_sizes.append(img.size)\n",
        "\n",
        "print(set(image_sizes))  # Unique image sizes\n",
        "\n",
        "# data distribution"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:50:43.30404Z",
          "iopub.execute_input": "2025-03-04T02:50:43.304213Z",
          "iopub.status.idle": "2025-03-04T02:51:23.173406Z",
          "shell.execute_reply.started": "2025-03-04T02:50:43.304198Z",
          "shell.execute_reply": "2025-03-04T02:51:23.172654Z"
        },
        "id": "yKcOeu4S1mpZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "class_counts = [len(os.listdir(os.path.join(data_dir, cls))) for cls in classes]\n",
        "sns.barplot(x=classes, y=class_counts)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:51:23.175945Z",
          "iopub.execute_input": "2025-03-04T02:51:23.176176Z",
          "iopub.status.idle": "2025-03-04T02:51:23.918018Z",
          "shell.execute_reply.started": "2025-03-04T02:51:23.176158Z",
          "shell.execute_reply": "2025-03-04T02:51:23.917074Z"
        },
        "id": "DQpq1sfd1mpZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(len(classes), 5, figsize=(15, len(classes) * 3))\n",
        "for i, cls in enumerate(classes):\n",
        "    class_dir = os.path.join(data_dir, cls)\n",
        "    for j in range(5):\n",
        "        img_path = os.path.join(class_dir, random.choice(os.listdir(class_dir)))\n",
        "        img = Image.open(img_path)\n",
        "        axes[i, j].imshow(img)\n",
        "        axes[i, j].axis(\"off\")\n",
        "        if j == 0:\n",
        "            axes[i, j].set_title(cls)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:51:23.919784Z",
          "iopub.execute_input": "2025-03-04T02:51:23.920298Z",
          "iopub.status.idle": "2025-03-04T02:51:26.029715Z",
          "shell.execute_reply.started": "2025-03-04T02:51:23.920271Z",
          "shell.execute_reply": "2025-03-04T02:51:26.02885Z"
        },
        "id": "ksrCLX3J1mpZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "0A3URkh31mpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Path to the Mango Leaf dataset\n",
        "data_dir = \"/kaggle/input/mango-leafbd/MangoLeafBD Dataset\"  # Update this path according to your dataset location\n",
        "\n",
        "# Visualizing a few random images from the Mango Leaf dataset\n",
        "def visualize_images(data_dir):\n",
        "    class_names = os.listdir(data_dir)\n",
        "    fig, axes = plt.subplots(1, len(class_names), figsize=(15, 5))\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        image_file = random.choice(os.listdir(class_dir))\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "\n",
        "        img = Image.open(image_path)\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(class_name)\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualize_images(data_dir)\n",
        "\n",
        "# Data augmentation pipeline\n",
        "transform_pipeline = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize all images to 224x224\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
        "    transforms.RandomRotation(20),  # Randomly rotate the image by 20 degrees\n",
        "    transforms.ToTensor(),  # Convert the image to a tensor\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
        "])\n",
        "\n",
        "# Create a dataset using ImageFolder and apply the transform pipeline\n",
        "image_dataset = datasets.ImageFolder(root=data_dir, transform=transform_pipeline)\n",
        "dataloader = torch.utils.data.DataLoader(image_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Visualize augmented images\n",
        "def visualize_augmented_images(dataloader):\n",
        "    images, labels = next(iter(dataloader))\n",
        "    fig, axes = plt.subplots(1, len(images[:5]), figsize=(15, 5))\n",
        "\n",
        "    for i in range(5):\n",
        "        img = images[i].permute(1, 2, 0).numpy()  # Convert from (C, H, W) to (H, W, C)\n",
        "        img = img * 0.5 + 0.5  # Denormalize the image for visualization\n",
        "\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(image_dataset.classes[labels[i]])\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualize_augmented_images(dataloader)\n",
        "\n",
        "# Apply more custom augmentations\n",
        "print(\"Applying custom augmentation and transformations\")\n",
        "custom_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color jitter\n",
        "    transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Random affine transformations\n",
        "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
        "    transforms.RandomRotation(20),  # Random rotation of up to 20 degrees\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
        "])\n",
        "\n",
        "# Create a dataset with custom augmentations\n",
        "augmented_dataset = datasets.ImageFolder(root=data_dir, transform=custom_transform)\n",
        "augmented_loader = torch.utils.data.DataLoader(augmented_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Visualize augmented images with custom transformations\n",
        "visualize_augmented_images(augmented_loader)\n",
        "\n",
        "# Feature engineering: Compute mean and standard deviation of images in the dataset\n",
        "def compute_features(loader):\n",
        "    features = []\n",
        "    for images, labels in loader:\n",
        "        for img in images:\n",
        "            mean = img.mean().item()\n",
        "            std = img.std().item()\n",
        "            features.append((mean, std))\n",
        "    return features\n",
        "\n",
        "features = compute_features(dataloader)\n",
        "\n",
        "# Print feature engineering results\n",
        "print(\"Feature Engineering Results:\")\n",
        "for i, (mean, std) in enumerate(features[:5]):\n",
        "    print(f\"Image {i+1}: Mean = {mean:.4f}, Std = {std:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:51:26.030709Z",
          "iopub.execute_input": "2025-03-04T02:51:26.030985Z",
          "iopub.status.idle": "2025-03-04T02:51:56.034878Z",
          "shell.execute_reply.started": "2025-03-04T02:51:26.030962Z",
          "shell.execute_reply": "2025-03-04T02:51:56.034115Z"
        },
        "id": "jjTrImr_1mpZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from graphviz import Digraph"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:51:56.035638Z",
          "iopub.execute_input": "2025-03-04T02:51:56.036183Z",
          "iopub.status.idle": "2025-03-04T02:51:56.299855Z",
          "shell.execute_reply.started": "2025-03-04T02:51:56.036159Z",
          "shell.execute_reply": "2025-03-04T02:51:56.299173Z"
        },
        "id": "h5FxfpRj1mpZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# an image dataset by converting image files into numerical values suitable for machine learning models."
      ],
      "metadata": {
        "id": "gHwTpiAk1mpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the directory where the images are stored\n",
        "image_dir = '/kaggle/input/mango-leafbd/MangoLeafBD Dataset'  # Replace with your directory path\n",
        "categories = os.listdir(image_dir)  # List of subfolder names (i.e., class labels)\n",
        "\n",
        "# Load the images and labels\n",
        "data = []    # Stores numerical representations (flattened pixel values) of images.\n",
        "labels = []   # Stores the class/category each image belongs to.\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(image_dir, category)\n",
        "    for image_file in os.listdir(category_path):\n",
        "        image_path = os.path.join(category_path, image_file)\n",
        "\n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Convert the image from BGR (OpenCV default) to RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Resize image to 64x64 (you can change this size as needed)\n",
        "        image = cv2.resize(image, (64, 64))\n",
        "\n",
        "        # Flatten the image from 3D to 1D\n",
        "        image = image.flatten()\n",
        "\n",
        "        data.append(image)\n",
        "        labels.append(category)\n",
        "\n",
        "# Convert the list of data into a numpy array\n",
        "X = np.array(data)  # Features (flattened images)\n",
        "y = np.array(labels)  # Labels (class/category)\n",
        "\n",
        "# Create a DataFrame with the image data and labels\n",
        "df = pd.DataFrame(X)\n",
        "df['label'] = y  # Add labels as a new column\n",
        "\n",
        "# Check the shape of the data and print the first few rows\n",
        "print(df.head())\n",
        "print(f\"Shape of feature matrix (X): {X.shape}\")\n",
        "print(f\"Shape of labels (y): {y.shape}\")\n",
        "\n",
        "# Now `X` contains the numerical representations of the images and `y` contains their corresponding labels.\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:51:56.300611Z",
          "iopub.execute_input": "2025-03-04T02:51:56.300925Z",
          "iopub.status.idle": "2025-03-04T02:52:08.981885Z",
          "shell.execute_reply.started": "2025-03-04T02:51:56.300903Z",
          "shell.execute_reply": "2025-03-04T02:52:08.980927Z"
        },
        "id": "3aJ7EMZZ1mpa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df.shape)\n",
        "print(df.describe())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:52:08.983022Z",
          "iopub.execute_input": "2025-03-04T02:52:08.983417Z",
          "iopub.status.idle": "2025-03-04T02:52:27.303219Z",
          "shell.execute_reply.started": "2025-03-04T02:52:08.983381Z",
          "shell.execute_reply": "2025-03-04T02:52:27.302311Z"
        },
        "id": "prBF4m-21mpa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Test"
      ],
      "metadata": {
        "id": "ThWm9VUa1mpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the features (X) and the target (y)\n",
        "X = df.drop(columns=['label'])  # Drop the 'label' column to get features\n",
        "y = df['label']  # Target variable\n",
        "\n",
        "# Split the dataset into 80% training and 20% testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Check the shape of train and test sets\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:52:27.304048Z",
          "iopub.execute_input": "2025-03-04T02:52:27.304281Z",
          "iopub.status.idle": "2025-03-04T02:52:27.535786Z",
          "shell.execute_reply.started": "2025-03-04T02:52:27.304251Z",
          "shell.execute_reply": "2025-03-04T02:52:27.535005Z"
        },
        "id": "p3ov5cDy1mpa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision tree classifier usning"
      ],
      "metadata": {
        "id": "1DeINa1d1mpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a decision tree classifier with gini criterion and maximum depth of 3\n",
        "dt = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)\n",
        "# Fit the model on the train data\n",
        "dt.fit(X_train, y_train)\n",
        "# Make predictions on the test data\n",
        "y_pred = dt.predict(X_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:52:27.536727Z",
          "iopub.execute_input": "2025-03-04T02:52:27.537041Z",
          "iopub.status.idle": "2025-03-04T02:52:37.262571Z",
          "shell.execute_reply.started": "2025-03-04T02:52:27.537016Z",
          "shell.execute_reply": "2025-03-04T02:52:37.261646Z"
        },
        "id": "ZKb8nk9j1mpa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Evaluate and compare performance of Decision tree"
      ],
      "metadata": {
        "id": "oU57zgQO1mpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions with the Decision Tree model (or Random Forest if you are comparing both)\n",
        "y_pred = dt.predict(X_test)  # This is assuming 'dt' is your Decision Tree model\n",
        "\n",
        "# Calculate the accuracy, precision, recall, and f1-score\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='macro')\n",
        "rec = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {acc:.2f}\")\n",
        "print(f\"Precision: {prec:.2f}\")\n",
        "print(f\"Recall: {rec:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.imshow(cm, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:52:37.263466Z",
          "iopub.execute_input": "2025-03-04T02:52:37.263777Z",
          "iopub.status.idle": "2025-03-04T02:52:37.7162Z",
          "shell.execute_reply.started": "2025-03-04T02:52:37.263733Z",
          "shell.execute_reply": "2025-03-04T02:52:37.7154Z"
        },
        "id": "GamwgHdr1mpa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plot Decision tree"
      ],
      "metadata": {
        "id": "e3tMNUzG1mpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming `df` is the DataFrame that contains the Mango Leaf dataset\n",
        "\n",
        "# Prepare feature matrix (X) and target vector (y)\n",
        "X = df.drop(columns=['label']).values  # Features (flattened image data)\n",
        "y = df['label'].values  # Target labels\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Assuming that the labels are numerical, convert them to categorical class names\n",
        "# Replace 'label' with the corresponding column if necessary\n",
        "class_names = list(df['label'].unique())  # This will get the unique class names from your 'label' column\n",
        "feature_names = [f'Feature {i+1}' for i in range(X.shape[1])]  # Assuming features are unnamed, this will generate 'Feature 1', 'Feature 2', etc.\n",
        "\n",
        "# Plot the decision tree\n",
        "plt.figure(figsize=(20, 25))# 12, 8\n",
        "plot_tree(dt, feature_names=feature_names, class_names=[str(x) for x in class_names], filled=True)\n",
        "plt.title('Decision Tree for Mango Leaf Dataset')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:52:37.71694Z",
          "iopub.execute_input": "2025-03-04T02:52:37.717171Z",
          "iopub.status.idle": "2025-03-04T02:52:48.245207Z",
          "shell.execute_reply.started": "2025-03-04T02:52:37.717143Z",
          "shell.execute_reply": "2025-03-04T02:52:48.24434Z"
        },
        "id": "m0OrwVOO1mpa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Random Forest Creation and Training"
      ],
      "metadata": {
        "id": "lqZfQEMZ1mpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:52:48.246158Z",
          "iopub.execute_input": "2025-03-04T02:52:48.246539Z",
          "iopub.status.idle": "2025-03-04T02:52:48.266466Z",
          "shell.execute_reply.started": "2025-03-04T02:52:48.246493Z",
          "shell.execute_reply": "2025-03-04T02:52:48.265601Z"
        },
        "id": "vpdzzz6u1mpb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Accuracy: {accuracy:.2f}\")\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T02:54:18.082749Z",
          "iopub.execute_input": "2025-03-04T02:54:18.083108Z",
          "iopub.status.idle": "2025-03-04T02:54:34.803794Z",
          "shell.execute_reply.started": "2025-03-04T02:54:18.083079Z",
          "shell.execute_reply": "2025-03-04T02:54:34.802554Z"
        },
        "id": "5vYXWIWp1mpb"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}